{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2adbe058-e049-4cd2-b9de-1ca815714ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Sequence, Set\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualize_classes(df):\n",
    "    fig = plt.figure()\n",
    "    plt.scatter(df[\"Class\"], df.Y)\n",
    "    ax = fig.axes[0]\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_title(\"Diabetes Y Classes\")\n",
    "\n",
    "# Our custom Dataset. Useful reference:\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "class DiabetesDataset(Dataset):\n",
    "    df: pd.DataFrame\n",
    "\n",
    "    x_include: Set[str]\n",
    "    y_column: str\n",
    "    y_dtype: torch.dtype\n",
    "\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,\n",
    "                 x_include: Sequence[str],\n",
    "                 y_column: str,\n",
    "                 y_dtype: torch.dtype = torch.long,\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.x_include = set(x_include)\n",
    "        self.y_column = y_column\n",
    "        self.y_dtype = y_dtype\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index) -> torch.Tensor:\n",
    "        x = self.df.loc[index, (col in self.x_include for col in self.df.columns)].values\n",
    "        y = self.df.loc[index, self.df.columns == self.y_column].values\n",
    "        return (\n",
    "            torch.tensor(x).float(),\n",
    "            torch.tensor(y).squeeze().to(self.y_dtype))\n",
    "\n",
    "class ClassPredictor:\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 learning_rate: float = 0.1,\n",
    "    ):\n",
    "        num_stages = 6\n",
    "        layers = []\n",
    "        for i in range(1, num_stages):\n",
    "            layers.append(nn.Linear(in_features * i, in_features * (i + 1)))\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        self.model = nn.Sequential(\n",
    "            *layers,\n",
    "            nn.Linear(in_features * num_stages, out_features),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.loss = nn.NLLLoss()\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=learning_rate)\n",
    "\n",
    "    def forward_batch(self, batch, optimize: bool = True):\n",
    "        xs, ys = batch\n",
    "\n",
    "        if optimize:\n",
    "            # new batch, zero all gradients\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        # feed forwad\n",
    "        output = self.model(xs)\n",
    "\n",
    "        # compute loss and gradients\n",
    "        loss = self.loss(output, ys)\n",
    "        loss.backward()\n",
    "\n",
    "        if optimize:\n",
    "            # update model parameters\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # calculate the accuracy.\n",
    "        # `inferred_classes` gets, from each entry in the batch the highest probability class.\n",
    "        # then, we count how many classes the model got right, and divide by total classes\n",
    "        # in order to normalize for a relative error.\n",
    "        inferred_classes = output.argmax(dim=1)\n",
    "        accuracy = (inferred_classes == ys).sum() / len(ys)\n",
    "\n",
    "        return loss.detach(), accuracy.detach()\n",
    "\n",
    "    def forward(self, dataloader: DataLoader, optimize: bool = True):\n",
    "        total_batches = len(dataloader)\n",
    "\n",
    "        loss_sum = 0\n",
    "        accuracy_sum = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            loss, accuracy = self.forward_batch(batch, optimize=optimize)\n",
    "            loss_sum += loss\n",
    "            accuracy_sum += accuracy\n",
    "\n",
    "        return float(loss_sum) / total_batches, float(accuracy_sum) / total_batches\n",
    "\n",
    "    def train(self,\n",
    "              epochs: int,\n",
    "              dataloader: DataLoader,\n",
    "              plot: bool = False,\n",
    "              plot_suptitle: Optional[str] = None,\n",
    "        ):\n",
    "    \n",
    "        losses = torch.empty(epochs)\n",
    "        accuracies = torch.empty(epochs)\n",
    "\n",
    "        print(\"Training \", end=\"\")\n",
    "        for epoch in range(epochs):\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            loss, accuracy = self.forward(dataloader)\n",
    "            losses[epoch] = loss\n",
    "            accuracies[epoch] = accuracy\n",
    "        print()\n",
    "\n",
    "        if plot:\n",
    "            self.plot_train_results(plot_suptitle, losses, accuracies)\n",
    "\n",
    "        return losses[-1], accuracies[-1]\n",
    "\n",
    "    def plot_train_results(self, suptitle, losses, accuracies):\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle(suptitle)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Loss\")\n",
    "        plt.plot(range(len(losses)), losses)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(len(accuracies)), accuracies)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "\n",
    "    def evaluate_model(self, dataloader: DataLoader) -> float:\n",
    "        loss, accuracy = self.forward(dataloader, optimize=False)\n",
    "        return accuracy\n",
    "\n",
    "def partition_dataframe(df: pd.DataFrame, frac: float) -> pd.DataFrame:\n",
    "    a = df.copy()\n",
    "    b = a.sample(frac=frac)\n",
    "    \n",
    "    a.drop(b.index)\n",
    "    a = a.reset_index()\n",
    "    b = b.reset_index()\n",
    "\n",
    "    return a, b\n",
    "\n",
    "def train_and_evaluate(\n",
    "        training_dataset: Dataset, test_dataset: Dataset,\n",
    "        output_features: int,\n",
    "        experiment_name: str, experiment_variant: str):\n",
    "    input_features = len(training_dataset[0][0])\n",
    "\n",
    "    predictor = ClassPredictor(\n",
    "        in_features=input_features,\n",
    "        out_features=output_features,\n",
    "        learning_rate=lr)\n",
    "\n",
    "    _, training_accuracy = predictor.train(\n",
    "        epochs,\n",
    "        DataLoader(training_dataset, batch_size),\n",
    "        plot=plot,\n",
    "        plot_suptitle=f\"{experiment_name} - {experiment_variant}\")\n",
    "\n",
    "    test_accuracy = predictor.evaluate_model(\n",
    "        DataLoader(test_dataset))\n",
    "\n",
    "    print(f\"Experiment: {experiment_name}, {experiment_variant}\")\n",
    "    print(f\" - Final training accuracy: {training_accuracy}\")\n",
    "    print(f\" - Final test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e646f-a681-4788-b999-9931d3e48d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "plot = True\n",
    "lr = 0.01\n",
    "batch_size = 10\n",
    "\n",
    "print(\"Epochs: \", epochs)\n",
    "print(\"Learning Rate: \", lr)\n",
    "print(\"Batch Size: \", batch_size)\n",
    "\n",
    "diabetes_df = pd.read_csv(\"assets/diabetes.csv\", sep=\"\\t\")\n",
    "\n",
    "def run_experiments(quantiles, variant_name):\n",
    "    diabetes_df['Class'] = pd.qcut(diabetes_df.Y, quantiles, labels=False)\n",
    "\n",
    "    # The training and test set contains 80% and 20% from the dataset respectively.\n",
    "    training_df, test_df = partition_dataframe(diabetes_df, frac=0.2)\n",
    "\n",
    "    training_dataset_with_y = DiabetesDataset(\n",
    "        training_df,\n",
    "        x_include=[col for col in diabetes_df.columns if col not in (\"Class\")],\n",
    "        y_column=\"Class\")\n",
    "\n",
    "    test_dataset_with_y = DiabetesDataset(\n",
    "        test_df,\n",
    "        x_include=[col for col in diabetes_df.columns if col not in (\"Class\")],\n",
    "        y_column=\"Class\")\n",
    "\n",
    "    training_dataset_without_y = DiabetesDataset(\n",
    "        training_df,\n",
    "        x_include=[col for col in diabetes_df.columns if col not in (\"Class\", \"Y\")],\n",
    "        y_column=\"Class\")\n",
    "\n",
    "    test_dataset_without_y = DiabetesDataset(\n",
    "        test_df,\n",
    "        x_include=[col for col in diabetes_df.columns if col not in (\"Class\", \"Y\")],\n",
    "        y_column=\"Class\")\n",
    "\n",
    "    # Visualize the quantiles\n",
    "    visualize_classes(diabetes_df)\n",
    "\n",
    "    if quantiles == 0:\n",
    "        # Just print, like required in the mmn\n",
    "        print(next(iter(DataLoader(training_dataset_with_y, batch_size))))\n",
    "\n",
    "    # Train and evaluate a predictor for Class that is trained on all fields including Y\n",
    "    train_and_evaluate(training_dataset_with_y, test_dataset_with_y,\n",
    "                       quantiles,\n",
    "                       \"Predict Class with Y\", variant_name)\n",
    "\n",
    "    # Train and evaluate a predictor for Class that is trained on all fields except Y\n",
    "    train_and_evaluate(training_dataset_without_y, test_dataset_without_y,\n",
    "                       quantiles,\n",
    "                       \"Predict Class without Y\", variant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7020b1fd-545a-4e13-8d24-fc2d9d551f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(10, \"Deciles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e4889-0ae5-434f-92fa-a58ab171f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(100, \"Percentiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb58bb-26a3-4b2b-ae66-5439ff190295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureRegression:\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 learning_rate: float = 0.1,\n",
    "    ):\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features * 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features * 2, 1),\n",
    "        )\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=learning_rate)\n",
    "\n",
    "    def forward_batch(self, batch, optimize: bool = True):\n",
    "        xs, ys = batch\n",
    "\n",
    "        if optimize:\n",
    "            # new batch, zero all gradients\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        # feed forwad\n",
    "        output = self.model(xs).squeeze()\n",
    "\n",
    "        # compute loss and gradients\n",
    "        loss = self.loss(output, ys)\n",
    "        loss.backward()\n",
    "\n",
    "        if optimize:\n",
    "            # update model parameters\n",
    "            self.optimizer.step()\n",
    "\n",
    "        # average distance \n",
    "        err = torch.abs(output - ys).mean()\n",
    "\n",
    "        return loss.detach(), err.detach()\n",
    "\n",
    "    def forward(self, dataloader: DataLoader, optimize: bool = True):\n",
    "        total_batches = len(dataloader)\n",
    "\n",
    "        loss_sum = 0\n",
    "        err_sum = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            loss, err = self.forward_batch(batch, optimize=optimize)\n",
    "            loss_sum += loss\n",
    "            err_sum += err\n",
    "\n",
    "        return float(loss_sum) / total_batches, float(err_sum) / total_batches\n",
    "\n",
    "    def train(self,\n",
    "              epochs: int,\n",
    "              dataloader: DataLoader,\n",
    "              plot: bool = False,\n",
    "              plot_suptitle: Optional[str] = None,\n",
    "        ):\n",
    "    \n",
    "        losses = torch.empty(epochs)\n",
    "        errors = torch.empty(epochs)\n",
    "\n",
    "        print(\"Training \", end=\"\")\n",
    "        for epoch in range(epochs):\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "            loss, accuracy = self.forward(dataloader)\n",
    "            losses[epoch] = loss\n",
    "            errors[epoch] = accuracy\n",
    "        print()\n",
    "\n",
    "        if plot:\n",
    "            self.plot_train_results(plot_suptitle, losses, errors)\n",
    "\n",
    "        return losses[-1], errors[-1]\n",
    "\n",
    "    def plot_train_results(self, suptitle, losses, errors):\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle(suptitle)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Loss\")\n",
    "        plt.plot(range(len(losses)), losses)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(len(errors)), errors)\n",
    "        plt.title(\"Error\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "\n",
    "    def evaluate_model(self, dataloader: DataLoader) -> float:\n",
    "        _, err = self.forward(dataloader, optimize=False)\n",
    "        return err "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44bab5-41cd-40f3-8b75-9f7cf46e944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "plot = True\n",
    "lr = 0.001\n",
    "batch_size = 10\n",
    "\n",
    "training_df, test_df = partition_dataframe(diabetes_df, frac=0.2)\n",
    "\n",
    "training_dataset_for_regression = DiabetesDataset(\n",
    "    training_df,\n",
    "    x_include=(col for col in training_df.columns if col != 'Y'),\n",
    "    y_column='Y', y_dtype=torch.float)\n",
    "\n",
    "test_dataset_for_regression = DiabetesDataset(\n",
    "    test_df,\n",
    "    x_include=(col for col in training_df.columns if col != 'Y'),\n",
    "    y_column='Y', y_dtype=torch.float)\n",
    "\n",
    "regression = FeatureRegression(len(training_df.columns) - 1, learning_rate=lr)\n",
    "\n",
    "train_loss, train_err = regression.train(\n",
    "    epochs, DataLoader(training_dataset_for_regression, batch_size), plot, \"Y Regression\")\n",
    "\n",
    "test_err = regression.evaluate_model(DataLoader(test_dataset_for_regression, batch_size))\n",
    "\n",
    "print(f\"Experiment: Y Regression\")\n",
    "print(f\" - Final training error: {train_err}\")\n",
    "print(f\" - Final test error: {test_err}\")\n",
    "\n",
    "for (xs, ys) in DataLoader(test_dataset_for_regression, batch_size=1):\n",
    "    result = regression.model(xs)\n",
    "    print(f\"Model: {result[0].item()}, Actual: {ys[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
