{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6848fe8-6a4a-4746-a430-0dbc1a8d7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed so the MyScalar type can use the MyScalar type in its definition\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random, randint\n",
    "from typing import Callable, List, Mapping, Optional, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0fc43-2b7c-47cb-bdf5-acb1890834b1",
   "metadata": {},
   "source": [
    "# Answer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e0ea33-50cf-4c10-ab0c-07aad6d9edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AliasTable:\n",
    "    \"\"\"\n",
    "    An Alias Table used to draw a sample in O(1).\n",
    "    \n",
    "    The implementation is based on the paper:\n",
    "    https://link.springer.com/chapter/10.1007/978-1-4842-7185-8_21\n",
    "\n",
    "    Throughout the implementation, we used the same symbols as in the\n",
    "    paper as much as possible.\n",
    "    \"\"\"\n",
    "    \n",
    "    table: List[Tuple[float, int, int]]\n",
    "\n",
    "    def __init__(self, distribution: List[float]):\n",
    "        self.table = AliasTable.construct(distribution)\n",
    "\n",
    "    def sample(self) -> float:\n",
    "        uniform_bin = randint(0, len(self.table) - 1) \n",
    "        epsilon = random()\n",
    "        tau, i, j = self.table[uniform_bin]\n",
    "        return i if epsilon < tau else j\n",
    "\n",
    "    @staticmethod\n",
    "    def construct(distribution: List[float]) -> List[Tuple[float, int, int]]:\n",
    "\n",
    "        N = len(distribution)\n",
    "        w = sum(distribution) / N\n",
    "\n",
    "        remaining = list(enumerate(distribution))\n",
    "\n",
    "        table = []\n",
    "        \n",
    "        while remaining:\n",
    "            # sort by weight\n",
    "            remaining.sort(key=lambda e: e[1])\n",
    "            print(remaining)\n",
    "            \n",
    "            # i is the sample and wi is the weight of the sample\n",
    "            i, wi = remaining[0]\n",
    "            \n",
    "            tau = wi / w        \n",
    "\n",
    "            # j is the highest weighted sample\n",
    "            j = remaining[-1][0]\n",
    "\n",
    "            wj = remaining[-1][1]\n",
    "\n",
    "            remaining[-1] = (j, 2*wj - w)\n",
    "\n",
    "            # append an entry to the table\n",
    "            table.append((tau, i, j))\n",
    "\n",
    "            # remove sample i\n",
    "            remaining.pop(0)\n",
    "\n",
    "        return table\n",
    "\n",
    "\n",
    "def sample_from_distribution(dist: List[float]) -> int:\n",
    "    \"\"\" Sample from the distribution in O(n) \"\"\"\n",
    "    \n",
    "    u = torch.rand([1])[0]\n",
    "    \n",
    "    if not (torch.tensor(dist) >= 0).all():\n",
    "        raise Exception(\"Invalid distribution: all probabilities must be non-negative\")\n",
    "\n",
    "    if not (torch.tensor(dist).sum() == 1):\n",
    "        raise Exception(\"Invalid distribution: measure must be 1\")\n",
    "\n",
    "    acc = 0\n",
    "    for i, v in enumerate(dist):\n",
    "        if u <= acc + v:\n",
    "            return i\n",
    "\n",
    "        acc += v\n",
    "\n",
    "    assert False, \"Unreachable\"\n",
    "\n",
    "def my_sampler(size: Sequence[int], dist: List[float], requires_grad: bool = False) -> torch.Tensor:\n",
    "    alias_table = AliasTable(dist)\n",
    "    tensor = torch.empty(size).apply_(lambda _: alias_table.sample())\n",
    "    tensor.requires_grad = requires_grad\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07db386-9f2a-4e77-9877-a4f80812f7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.1), (1, 0.2), (2, 0.7)]\n",
      "[(1, 0.2), (2, 1.0666666666666667)]\n",
      "[(2, 1.8)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sample_and_plot_histogram(n: int, dist: List[float]):\n",
    "    m = len(dist)\n",
    "    tensor = my_sampler((n, ), dist)\n",
    "    plt.figure()\n",
    "    plt.bar(x=range(m), height=tensor.histc(m))\n",
    "    plt.title(f\"Histogram of {n} samples from the distribution {dist}\")\n",
    "    plt.xticks(range(m))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "sample_and_plot_histogram(10_000, [0.1, 0.2, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587e97e-f35e-425c-a32d-58181be087c0",
   "metadata": {},
   "source": [
    "# Answer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b312d4b-a919-41df-aceb-2cdc61ee5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyScalar:\n",
    "\n",
    "    # The value contained in this object.\n",
    "    value: float\n",
    "\n",
    "    # A list of `MyScalar`s that this object is created from.\n",
    "    parents: List[\"MyScalar\"]\n",
    "\n",
    "    # The immediate derivative of the operation created this object\n",
    "    # with respect to each of its parents.\n",
    "    grad: Mapping[int, float]\n",
    "\n",
    "    def __init__(self,\n",
    "                 value: float,\n",
    "                 parents: Optional[List[\"MyScalar\"]] = None,\n",
    "                 grad: Optional[Mapping[int, float]] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize a new MyScalar.\n",
    "\n",
    "        Usually you would instantiate a new MyScalar object as such:\n",
    "\n",
    "            MyScalar(5)\n",
    "\n",
    "        The default arguments are used by our autograd implementation.    \n",
    "        \"\"\"\n",
    "        self.value = value\n",
    "        self.parents = [] if parents is None else parents\n",
    "        self.grad = { id(self): 1.0 } if grad is None else grad\n",
    "\n",
    "    def add(self: MyScalar, other: float) -> MyScalar:\n",
    "        \"\"\" Adds `self` to another `float` \"\"\"\n",
    "        value = self.value + other \n",
    "        parents = [self]\n",
    "\n",
    "        # Df/Dself=1\n",
    "        grad = { id(self): 1 }\n",
    "\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def __add__(self: MyScalar, rhs: MyScalar) -> MyScalar:\n",
    "        value = self.value + rhs.value\n",
    "        parents = [self, rhs]\n",
    "        grad = {\n",
    "                id(self): 1,\n",
    "                id(rhs): 1,\n",
    "                }\n",
    "\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def __sub__(self: MyScalar, rhs: MyScalar) -> MyScalar:\n",
    "        value = self.value - rhs.value\n",
    "        parents = [self, rhs]\n",
    "        grad = {\n",
    "                id(self): 1,\n",
    "                id(rhs): -1,\n",
    "                }\n",
    "\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def sub(self: MyScalar, rhs: float) -> MyScalar:\n",
    "        value = self.value - rhs\n",
    "        parents = [self]\n",
    "        grad = { id(self): 1 }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def __mul__(self: MyScalar, rhs: MyScalar) -> MyScalar:\n",
    "        value = self.value * rhs.value\n",
    "        parents = [self, rhs]\n",
    "        grad = {\n",
    "                id(self): rhs.value,\n",
    "                id(rhs): self.value\n",
    "                }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def mul(self: MyScalar, rhs: float) -> MyScalar:\n",
    "        value = self.value * rhs\n",
    "        parents = [self]\n",
    "        grad = { id(self): rhs }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def __truediv__(self: MyScalar, divisor: MyScalar) -> MyScalar:\n",
    "        assert divisor.value != 0, \"Divisor should be non-zero\"\n",
    "        value = self.value / divisor.value\n",
    "        parents = [self, divisor]\n",
    "        grad = {\n",
    "                id(self): 1 / divisor.value,\n",
    "                id(divisor): self.value * -1 / (divisor.value**2)\n",
    "                }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def div(self: MyScalar, divisor: float) -> MyScalar:\n",
    "        assert divisor != 0, \"Divisor should be non-zero\"\n",
    "        value = self.value * divisor\n",
    "        parents = [self, divisor]\n",
    "        grad = { id(self): 1 / divisor }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def pow(self: MyScalar, exponent: float) -> MyScalar:\n",
    "        value = math.pow(self.value, exponent)\n",
    "        parents = [self]\n",
    "        grad = { id(self): exponent * math.pow(self.value, exponent - 1) }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def exp(self: MyScalar) -> MyScalar:\n",
    "        value = math.exp(self.value)\n",
    "        parents = [self]\n",
    "        grad = { id(self): value }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def cos(self: MyScalar) -> MyScalar:\n",
    "        value = math.cos(self.value)\n",
    "        parents = [self]\n",
    "        grad = { id(self): -1 * math.sin(self.value) }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def sin(self: MyScalar) -> MyScalar:\n",
    "        value = math.sin(self.value)\n",
    "        parents = [self]\n",
    "        grad = { id(self): math.cos(self.value) }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "    def log(self: MyScalar) -> MyScalar:\n",
    "        assert self.value > 0, \"Log operand must be positive\"\n",
    "\n",
    "        value = math.log(self.value)\n",
    "        parents = [self]\n",
    "        grad = { id(self): 1 / self.value }\n",
    "        return MyScalar(value, parents, grad)\n",
    "\n",
    "\n",
    "    def get_gradient(\n",
    "            self: MyScalar,\n",
    "            aliases: Optional[Mapping[int, str]] = None,\n",
    "    ) -> Mapping[str, float]:\n",
    "        \"\"\" Traverse the computational graph and calculate the gradient \"\"\"\n",
    "        \n",
    "        # Immediate gradients are the basecase\n",
    "        grad = dict(self.grad)\n",
    "\n",
    "        # Run dfs on the graph, compute the derivatives according to the chain rule.\n",
    "        stack = list(self.parents)\n",
    "\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "\n",
    "            for parent in node.parents:\n",
    "                # addititive residuals, multiplicative chain rule \n",
    "                grad[id(parent)] = grad.get(id(parent), 0) + (grad[id(node)] * node.grad[id(parent)])\n",
    "                stack.append(parent)\n",
    "\n",
    "        ans = {}\n",
    "        aliases = aliases or {}\n",
    "        for k, v in (grad).items():\n",
    "            if k in aliases:\n",
    "                ans[aliases.get(k, str(k))] = v\n",
    "\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d605972-6b14-4636-9017-ca74fe020fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp\n",
      " - a, error=0.0, custom_grad=1.555506923947372, torch_grad=1.555506944656372\n",
      "\n",
      "a + b\n",
      " - a, error=0.0, custom_grad=1, torch_grad=1.0\n",
      "\n",
      " - b, error=0.0, custom_grad=1, torch_grad=1.0\n",
      "\n",
      "a - b\n",
      " - a, error=0.0, custom_grad=1, torch_grad=1.0\n",
      "\n",
      " - b, error=-0.0, custom_grad=-1, torch_grad=-1.0\n",
      "\n",
      "a * b\n",
      " - a, error=0.0, custom_grad=0.03279016524671019, torch_grad=0.0327901653945446\n",
      "\n",
      " - b, error=0.0, custom_grad=0.4715543463891513, torch_grad=0.47155433893203735\n",
      "\n",
      "a / b\n",
      " - a, error=0.0, custom_grad=2.9146548198412834, torch_grad=2.9146547317504883\n",
      "\n",
      " - b, error=-0.0, custom_grad=-1.1783185632242437, torch_grad=-1.1783186197280884\n",
      "\n",
      "ln\n",
      " - a, error=0.0, custom_grad=2.293826397529669, torch_grad=2.2938263416290283\n",
      "\n",
      "large power\n",
      " - a, error=0.0, custom_grad=0.9852035229812433, torch_grad=0.9852036833763123\n",
      "\n",
      "zero power\n",
      " - a, error=0.0, custom_grad=0.0, torch_grad=0.0\n",
      "\n",
      "fractional power\n",
      " - a, error=0.0, custom_grad=0.5541547092684139, torch_grad=0.5541546940803528\n",
      "\n",
      "negative power\n",
      " - a, error=-0.0, custom_grad=-144.05118738081165, torch_grad=-144.05116271972656\n",
      "\n",
      "cos\n",
      " - a, error=-0.0, custom_grad=-0.5629345502988594, torch_grad=-0.5629345774650574\n",
      "\n",
      "sin\n",
      " - a, error=0.0, custom_grad=0.9999977086617493, torch_grad=0.9999977350234985\n",
      "\n",
      "complex graph, such that a is used in more than one branch\n",
      " - a, error=-0.0, custom_grad=-38.02715766795005, torch_grad=-38.02714538574219\n",
      "\n",
      " - d, error=0.0, custom_grad=20.857299037026575, torch_grad=20.857295989990234\n",
      "\n",
      " - c, error=-0.0, custom_grad=-7.832941813648879, torch_grad=-7.832941055297852\n",
      "\n",
      " - b, error=-0.0, custom_grad=-18.953171870380817, torch_grad=-18.95316505432129\n",
      "\n",
      "chain operations\n",
      " - a, error=-0.0, custom_grad=-30.498650355718162, torch_grad=-30.498655319213867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Tester:\n",
    "    \"\"\" Testing functionality.\n",
    "    Provides mechanisms to operate on either torch.tensor or MyScalar seemlessly\n",
    "    and calculates a relative error between the results.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_torch_grad(initializers, f):\n",
    "        tensors = [\n",
    "                torch.tensor(initializer, requires_grad=True)\n",
    "                for initializer\n",
    "                in initializers]\n",
    "\n",
    "        ans = f(*tensors)\n",
    "        ans.backward()\n",
    "\n",
    "        grad = {}\n",
    "        for i, tensor in enumerate(tensors):\n",
    "            name = chr(ord('a') + i)\n",
    "            grad[name] = tensor.grad.item()\n",
    "\n",
    "        return grad\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_custom_grad(initializers, f):\n",
    "        myscalars = [MyScalar(initializer) for initializer in initializers]\n",
    "\n",
    "        # Invoke the function\n",
    "        ans = f(*myscalars)\n",
    "\n",
    "        # Build the aliases so the keys won't be ids but names \"a\", \"b\", \"c\", ...\n",
    "        aliases = {}\n",
    "        for i, myscalar in enumerate(myscalars):\n",
    "            name = chr(ord('a') + i)\n",
    "            aliases[id(myscalar)] = name\n",
    "\n",
    "        # Get the gradient\n",
    "        return ans.get_gradient(aliases)\n",
    "\n",
    "    @staticmethod\n",
    "    def error(a, b):\n",
    "        \"\"\" Calculate the relative error between a and b \"\"\"\n",
    "        if max(a, b) == 0:\n",
    "            return min(a, b)\n",
    "        return abs(a - b) / max(a, b)\n",
    "\n",
    "    @staticmethod\n",
    "    def run(name, argc, f):\n",
    "        \"\"\"\n",
    "        Applies `f` twice - Once on `argc` arguments of type `torch.tensor`\n",
    "        and once on `argc` arguments of type `MyScalar`.\n",
    "\n",
    "        \n",
    "        `f` is assumed to return a mapping from string to\n",
    "        floats such that the keys are the named variables and the values are the derivatives df/dv_i.\n",
    "        \n",
    "        i.e., `f` returns the gradient of `f` but instead in vector form, in keyed form.\n",
    "\n",
    "        Then, compare the derivatives of the two implementations (torch.tensor vs MyScalar).\n",
    "        If the relative error between to such derivatives is not negligible, raise an assertion error.\n",
    "        \"\"\"\n",
    "        print(f\"{name}\")\n",
    "\n",
    "        initializers = [random() for _ in range(argc)]\n",
    "        custom_grad = Tester.compute_custom_grad(initializers, f)\n",
    "        torch_grad = Tester.compute_torch_grad(initializers, f)\n",
    "\n",
    "        assert custom_grad.keys() == torch_grad.keys(), \"Torch and Custom grads yielded different leafs\"\n",
    "\n",
    "        for k, custom_val in custom_grad.items():\n",
    "            torch_val = torch_grad[k]\n",
    "            error = Tester.error(custom_val, torch_val) \n",
    "            print(f\" - {k}, error={round(error, 3)}, custom_grad={custom_val}, torch_grad={torch_val}\")\n",
    "            assert error < 0.1, f\"Torch and Custom grad[{k}] differ\"\n",
    "            print()\n",
    "\n",
    "# Multiple test cases to invoke using the Tester\n",
    "test_cases = [\n",
    "        (\"exp\", 1, lambda a: a.exp()),\n",
    "\n",
    "        (\"a + b\", 2, lambda a, b: a + b),\n",
    "        (\"a - b\", 2, lambda a, b: a - b),\n",
    "        (\"a * b\", 2, lambda a, b: a * b),\n",
    "        (\"a / b\", 2, lambda a, b: a / b),\n",
    "\n",
    "        (\"ln\", 1, lambda a: a.log()),\n",
    "\n",
    "        (\"large power\", 1, lambda a: a.pow(5)),\n",
    "        (\"zero power\", 1, lambda a: a.pow(0)),\n",
    "        (\"fractional power\", 1, lambda a: a.pow(0.3)),\n",
    "        (\"negative power\", 1, lambda a: a.pow(-4.0)),\n",
    "\n",
    "        (\"cos\", 1, lambda a: a.cos()),\n",
    "        (\"sin\", 1, lambda a: a.sin()),\n",
    "\n",
    "        (\"complex graph, such that a is used in more than one branch\",\n",
    "         4,\n",
    "         lambda a, b, c, d: ((a.log() / b.sin()) + (a.cos() * c) - (a + d.exp())).pow(2)\n",
    "         ),\n",
    "\n",
    "        (\"chain operations\",\n",
    "         1,\n",
    "         lambda a: a.pow(2).cos().sin().sin().exp().pow(3).log() / a + a * a\n",
    "         )\n",
    "    ]\n",
    "\n",
    "# Invoke all test cases using the Tester\n",
    "for name, argc, f in test_cases:\n",
    "    Tester.run(name, argc, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
