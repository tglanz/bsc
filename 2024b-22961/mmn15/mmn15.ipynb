{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXjenKz0ZAx8NcgelIXOoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tglanz/bsc/blob/master/2024b-22961/mmn15/mmn15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Vmzde2H3cXO",
        "outputId": "19306926-3b97-4ae2-84bf-57e7d66211ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "cuda:0\n",
            "FINISHED_BATCH: epoch=0, batch=0/196, accuracy=0.10546875\n",
            "FINISHED_BATCH: epoch=0, batch=1/196, accuracy=0.09765625\n",
            "FINISHED_BATCH: epoch=0, batch=2/196, accuracy=0.13671875\n",
            "FINISHED_BATCH: epoch=0, batch=3/196, accuracy=0.15625\n",
            "FINISHED_BATCH: epoch=0, batch=4/196, accuracy=0.20703125\n",
            "FINISHED_BATCH: epoch=0, batch=5/196, accuracy=0.23828125\n",
            "FINISHED_BATCH: epoch=0, batch=6/196, accuracy=0.234375\n",
            "FINISHED_BATCH: epoch=0, batch=7/196, accuracy=0.2734375\n",
            "FINISHED_BATCH: epoch=0, batch=8/196, accuracy=0.328125\n",
            "FINISHED_BATCH: epoch=0, batch=9/196, accuracy=0.296875\n",
            "FINISHED_BATCH: epoch=0, batch=10/196, accuracy=0.34765625\n",
            "FINISHED_BATCH: epoch=0, batch=11/196, accuracy=0.37890625\n",
            "FINISHED_BATCH: epoch=0, batch=12/196, accuracy=0.38671875\n",
            "FINISHED_BATCH: epoch=0, batch=13/196, accuracy=0.44140625\n",
            "FINISHED_BATCH: epoch=0, batch=14/196, accuracy=0.47265625\n",
            "FINISHED_BATCH: epoch=0, batch=15/196, accuracy=0.51953125\n",
            "FINISHED_BATCH: epoch=0, batch=16/196, accuracy=0.515625\n",
            "FINISHED_BATCH: epoch=0, batch=17/196, accuracy=0.4765625\n",
            "FINISHED_BATCH: epoch=0, batch=18/196, accuracy=0.54296875\n",
            "FINISHED_BATCH: epoch=0, batch=19/196, accuracy=0.52734375\n",
            "FINISHED_BATCH: epoch=0, batch=20/196, accuracy=0.484375\n",
            "FINISHED_BATCH: epoch=0, batch=21/196, accuracy=0.5703125\n",
            "FINISHED_BATCH: epoch=0, batch=22/196, accuracy=0.6171875\n",
            "FINISHED_BATCH: epoch=0, batch=23/196, accuracy=0.5390625\n",
            "FINISHED_BATCH: epoch=0, batch=24/196, accuracy=0.578125\n",
            "FINISHED_BATCH: epoch=0, batch=25/196, accuracy=0.59375\n",
            "FINISHED_BATCH: epoch=0, batch=26/196, accuracy=0.57421875\n",
            "FINISHED_BATCH: epoch=0, batch=27/196, accuracy=0.58984375\n",
            "FINISHED_BATCH: epoch=0, batch=28/196, accuracy=0.60546875\n",
            "FINISHED_BATCH: epoch=0, batch=29/196, accuracy=0.65625\n",
            "FINISHED_BATCH: epoch=0, batch=30/196, accuracy=0.61328125\n",
            "FINISHED_BATCH: epoch=0, batch=31/196, accuracy=0.65234375\n",
            "FINISHED_BATCH: epoch=0, batch=32/196, accuracy=0.6640625\n",
            "FINISHED_BATCH: epoch=0, batch=33/196, accuracy=0.6015625\n",
            "FINISHED_BATCH: epoch=0, batch=34/196, accuracy=0.63671875\n",
            "FINISHED_BATCH: epoch=0, batch=35/196, accuracy=0.6484375\n",
            "FINISHED_BATCH: epoch=0, batch=36/196, accuracy=0.6484375\n",
            "FINISHED_BATCH: epoch=0, batch=37/196, accuracy=0.69140625\n",
            "FINISHED_BATCH: epoch=0, batch=38/196, accuracy=0.65625\n",
            "FINISHED_BATCH: epoch=0, batch=39/196, accuracy=0.6484375\n",
            "FINISHED_BATCH: epoch=0, batch=40/196, accuracy=0.72265625\n",
            "FINISHED_BATCH: epoch=0, batch=41/196, accuracy=0.69921875\n",
            "FINISHED_BATCH: epoch=0, batch=42/196, accuracy=0.7109375\n",
            "FINISHED_BATCH: epoch=0, batch=43/196, accuracy=0.66796875\n",
            "FINISHED_BATCH: epoch=0, batch=44/196, accuracy=0.64453125\n",
            "FINISHED_BATCH: epoch=0, batch=45/196, accuracy=0.72265625\n",
            "FINISHED_BATCH: epoch=0, batch=46/196, accuracy=0.72265625\n",
            "FINISHED_BATCH: epoch=0, batch=47/196, accuracy=0.65234375\n",
            "FINISHED_BATCH: epoch=0, batch=48/196, accuracy=0.6796875\n",
            "FINISHED_BATCH: epoch=0, batch=49/196, accuracy=0.68359375\n",
            "FINISHED_BATCH: epoch=0, batch=50/196, accuracy=0.72265625\n",
            "FINISHED_BATCH: epoch=0, batch=51/196, accuracy=0.69140625\n",
            "FINISHED_BATCH: epoch=0, batch=52/196, accuracy=0.68359375\n",
            "FINISHED_BATCH: epoch=0, batch=53/196, accuracy=0.734375\n",
            "FINISHED_BATCH: epoch=0, batch=54/196, accuracy=0.69921875\n",
            "FINISHED_BATCH: epoch=0, batch=55/196, accuracy=0.69140625\n",
            "FINISHED_BATCH: epoch=0, batch=56/196, accuracy=0.68359375\n",
            "FINISHED_BATCH: epoch=0, batch=57/196, accuracy=0.671875\n",
            "FINISHED_BATCH: epoch=0, batch=58/196, accuracy=0.67578125\n",
            "FINISHED_BATCH: epoch=0, batch=59/196, accuracy=0.69140625\n",
            "FINISHED_BATCH: epoch=0, batch=60/196, accuracy=0.734375\n",
            "FINISHED_BATCH: epoch=0, batch=61/196, accuracy=0.7109375\n",
            "FINISHED_BATCH: epoch=0, batch=62/196, accuracy=0.7265625\n",
            "FINISHED_BATCH: epoch=0, batch=63/196, accuracy=0.6796875\n",
            "FINISHED_BATCH: epoch=0, batch=64/196, accuracy=0.78515625\n",
            "FINISHED_BATCH: epoch=0, batch=65/196, accuracy=0.69921875\n",
            "FINISHED_BATCH: epoch=0, batch=66/196, accuracy=0.66796875\n",
            "FINISHED_BATCH: epoch=0, batch=67/196, accuracy=0.76953125\n",
            "FINISHED_BATCH: epoch=0, batch=68/196, accuracy=0.75\n",
            "FINISHED_BATCH: epoch=0, batch=69/196, accuracy=0.73046875\n",
            "FINISHED_BATCH: epoch=0, batch=70/196, accuracy=0.734375\n",
            "FINISHED_BATCH: epoch=0, batch=71/196, accuracy=0.78515625\n",
            "FINISHED_BATCH: epoch=0, batch=72/196, accuracy=0.73046875\n",
            "FINISHED_BATCH: epoch=0, batch=73/196, accuracy=0.70703125\n",
            "FINISHED_BATCH: epoch=0, batch=74/196, accuracy=0.73046875\n",
            "FINISHED_BATCH: epoch=0, batch=75/196, accuracy=0.69140625\n",
            "FINISHED_BATCH: epoch=0, batch=76/196, accuracy=0.7109375\n",
            "FINISHED_BATCH: epoch=0, batch=77/196, accuracy=0.69921875\n",
            "FINISHED_BATCH: epoch=0, batch=78/196, accuracy=0.75390625\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-933edc1843fa>\u001b[0m in \u001b[0;36m<cell line: 136>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m         device=device)\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-933edc1843fa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     replace_and_train_head(\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-933edc1843fa>\u001b[0m in \u001b[0;36mreplace_and_train_head\u001b[0;34m(model, data, class_count, batch_limit, device)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_limit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from typing import Optional\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "TRAINED_MEAN = [0.485, 0.456, 0.406]\n",
        "TRAINED_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def create_cifar_datasets():\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.PILToTensor(),\n",
        "        torchvision.transforms.ConvertImageDtype(torch.float),\n",
        "        torchvision.transforms.Resize(224),\n",
        "        torchvision.transforms.Normalize(mean=TRAINED_MEAN, std=TRAINED_STD)\n",
        "    ])\n",
        "\n",
        "    train = torchvision.datasets.CIFAR10(\"datasets\", train=True, download=True, transform=transform)\n",
        "    test = torchvision.datasets.CIFAR10(\"datasets\", train=False, download=True, transform=transform)\n",
        "\n",
        "    return train, test\n",
        "\n",
        "def plot_cifar_samples(cifar: torchvision.datasets.CIFAR10, samples_per_class: int = 3):\n",
        "\n",
        "    plt.figure()\n",
        "\n",
        "    class_counters = {\n",
        "        cifar.class_to_idx[clazz]: 0\n",
        "        for clazz\n",
        "        in cifar.classes\n",
        "    }\n",
        "\n",
        "    fig, axes = plt.subplots(len(class_counters), samples_per_class, figsize=(12, 12))\n",
        "    fig.tight_layout()\n",
        "\n",
        "    trained_std_tensor = torch.tensor(TRAINED_STD).unsqueeze(1).unsqueeze(1)\n",
        "    trained_mean_tensor = torch.tensor(TRAINED_MEAN).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "    for x, y in DataLoader(cifar):\n",
        "        y = y.item()\n",
        "        class_counter = class_counters[y]\n",
        "        if class_counter < 3:\n",
        "            grid_index = y * samples_per_class + class_counter\n",
        "            axes = plt.subplot(len(class_counters), samples_per_class, grid_index + 1)\n",
        "            axes.tick_params(which=\"both\", size=0, labelsize=0)\n",
        "            axes.set_title(cifar.classes[y])\n",
        "\n",
        "            x = x.squeeze(0)\n",
        "            x = x * trained_std_tensor + trained_mean_tensor\n",
        "            x = x.permute(1, 2, 0)\n",
        "            plt.imshow(x.numpy())\n",
        "            class_counters[y] += 1\n",
        "\n",
        "            # exit early without iterating the entire data set\n",
        "            if sum(class_counters.values()) == samples_per_class * len(class_counters):\n",
        "                break\n",
        "\n",
        "def load_resnet() -> torchvision.models.ResNet:\n",
        "    return torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "def replace_and_train_head(model: torch.nn.Module, data: DataLoader, class_count: int = 10, batch_limit: Optional[int] = None, device: torch.DeviceObjType = None):\n",
        "    device = device or torch.device(\"cpu\")\n",
        "\n",
        "    # Turn off grad tracking of all paramaeters\n",
        "    for parameter in model.parameters(recurse=True):\n",
        "        parameter.requires_grad = False\n",
        "\n",
        "    # Replace the fully connected layer with a new one to have the correct number of classes\n",
        "    original_fc = model.fc\n",
        "    model.fc = torch.nn.Linear(\n",
        "        original_fc.in_features, class_count,\n",
        "        bias=original_fc.bias is not None,\n",
        "        device=original_fc.weight.device,\n",
        "        dtype=original_fc.weight.dtype)\n",
        "\n",
        "\n",
        "    batches = len(data)\n",
        "    epochs = 2\n",
        "    accuracy_per_epoch = [0]*epochs\n",
        "\n",
        "    # Create the optimizer.\n",
        "    # Notice how we only provide the parameters of the newly created layer\n",
        "    optimizer = torch.optim.Adam(params=model.fc.parameters(), lr=0.001)\n",
        "    # optimizer = torch.optim.SGD(params=model.fc.parameters(), lr=0.1, momentum=0.9)\n",
        "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, last_epoch=-1)\n",
        "\n",
        "    # Loss function well suited for classification tasks\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    print(device)\n",
        "    model.to(device)\n",
        "    model.train(True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch_index, batch in enumerate(data):\n",
        "            if batch_limit and batch_index >= batch_limit:\n",
        "                break\n",
        "\n",
        "            xs, ys = batch\n",
        "            xs = xs.to(device)\n",
        "            ys = ys.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            ys_model = model(xs)\n",
        "            loss = loss_fn(ys_model, ys)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track the accuracies\n",
        "            inferred_classes = torch.argmax(ys_model, dim=1)\n",
        "            accuracy = (inferred_classes == ys).sum() / len(ys)\n",
        "            accuracy_per_epoch[epoch] += accuracy.item()\n",
        "\n",
        "            print(f\"FINISHED_BATCH: epoch={epoch}, batch={batch_index}/{batches}, accuracy={accuracy}\")\n",
        "\n",
        "        accuracy_per_epoch[epoch] /= batches\n",
        "        print(f\"FINISHED_EPOCH: epoch={epoch}, mean_accuracy={accuracy_per_epoch[epoch]*100:.2f}%\")\n",
        "        # scheduler.step(epoch)\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    print(device)\n",
        "\n",
        "    train_ds, test_ds = create_cifar_datasets()\n",
        "    # plot_cifar_samples(train_ds)\n",
        "\n",
        "    resnet = load_resnet()\n",
        "    replace_and_train_head(\n",
        "        resnet,\n",
        "        DataLoader(train_ds, shuffle=True, batch_size=256, num_workers=4),\n",
        "        device=device)\n",
        "\n",
        "main()"
      ]
    }
  ]
}