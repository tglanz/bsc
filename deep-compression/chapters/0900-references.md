# References

> Note: All links below redirect to the Open University's library

#### 1. [Learning both Weights and Connections for Efficient Neural Networks. 2015](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1506.02626&site=eds-live&scope=site) {#ref-1}

#### 2. [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding. 2015](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1510.00149&site=eds-live&scope=site) {#ref-2}

#### L1. [**The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks. 2018**](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1803.03635&site=eds-live&scope=site) {#ref-l1}

#### L2. [**Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask. 2019**](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1905.01067&site=eds-live&scope=site) {#ref-l2}

#### L3. [Gradient flow in sparse neural networks and how lottery tickets win. 2020](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2010.03533&site=eds-live&scope=site) {#ref-l3}

#### 6. (To Remove?) [A Survey on Deep Neural Network Compression: Challenges, Overview, and Solutions. 2020](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2010.03954&site=eds-live&scope=site) {#ref-6}

#### 7. [**What is the State of Neural Network Pruning?. 2020**](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2003.03033&site=eds-live&scope=site) {#ref-7}

#### 9. [**Comparing Rewinding and Fine-tuning in Neural Network Pruning. 2020**](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2003.02389&site=eds-live&scope=site) {#ref-9}

#### 10. [SONIC: A Sparse Neural Network Inference Accelerator with Silicon Photonics for Energy-Efficient Deep Learning. 2021](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2109.04459&site=eds-live&scope=site) {#ref-10}

#### 11. [**Unmasking the Lottery Ticket Hypothesis: What's encoded in a Winning Ticket's Mask?. 2022**](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2210.03044&site=eds-live&scope=site) {#ref-11}

#### C1. [DeepSZ: A Novel Framework to Compress Deep Neural Networks by Using Error-Bounded Lossy Compression. 2019](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.1901.09124&site=eds-live&scope=site) {#ref-c1}

#### C2. [Weightless: Lossy Weight Encoding For Deep Neural Network Compression. 2017]() {#ref-c2}

#### A1. [The Bloomier filter: an efficient data structure for static support lookup tables. 2004](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edscma&AN=edscma.982797&site=eds-live&scope=site) {#ref-a1}

#### Q1. [Neural Network Quantization for Efficient Inference: A Survey. 2023](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2112.06126&site=eds-live&scope=site) {#ref-q1}

#### Q2. [A White Paper on Neural Network Quantization. 2021](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2106.08295&site=eds-live&scope=site){#ref-q2}

#### Q3. [A Survey of Quantization Methods for Efficient Neural Network Inference. 2021](http://elib.openu.ac.il/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edsarx&AN=edsarx.2103.13630&site=eds-live&scope=site){#ref-q3}